

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

from sklearn.preprocessing import MinMaxScaler
import scipy.stats as stats
import statsmodels.api as sm

from IPython.display import display
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error, median_absolute_error, max_error, r2_score, explained_variance_score

import matplotlib.pyplot as plt
from matplotlib.dates import MonthLocator, DateFormatter, YearLocator
from tensorflow.keras.models import Sequential
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.layers import Dense, InputLayer, LSTM
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model

…Code in Sección  A …



# In[1754]:

######################################################################
######################################################################
######################################################################
######################################################################

DATAFORLSTM=SPAIN_scaled
# DATAFORLSTM=FRANCE_scaled
# DATAFORLSTM=ITALY_scaled
# DATAFORLSTM=GERMANY_scaled



DATAFORLSTM = DATAFORLSTM.drop(columns=[
    # 'POPULATION',
    # 'GDP',
    'GELEC R',
    'GELEC NR',
    # 'TRANSP',
    'METALI',
    # 'CONST'
])

######################################################################
######################################################################
######################################################################
######################################################################

WINDOW_SIZE = 1

def data_to_input_and_output(data):

    input_data = []
    output_data = []
    for index in range(0, len(data) - WINDOW_SIZE+1):
        X=data.copy()
        X=X.drop(columns=['YEAR','CO2 eq'])
        input_sample = X.iloc[index:index + WINDOW_SIZE]
        output_sample = data['CO2 eq'].iloc[index + WINDOW_SIZE-1]
        input_data.append(input_sample)
        output_data.append(output_sample)

    return np.array(input_data), np.array(output_data)


LSTM_input, LSTM_output=data_to_input_and_output(DATAFORLSTM)


train_size = int(len(LSTM_input) * 0.8)
print(train_size)

train, test = DATAFORLSTM.iloc[:train_size], DATAFORLSTM.iloc[train_size:]

train_input, test_input = LSTM_input[:train_size], LSTM_input[train_size:]
train_output, test_output = LSTM_output[:train_size], LSTM_output[train_size:]

# print(DATAFORLSTM.shape)
# print('------------')
# print(LSTM_input.shape)
# print(LSTM_output.shape)
# print('------------')
print(train_input.shape)
print(test_input.shape)
print('------------')
print(train_output.shape)
print(test_output.shape)
print('------------')

print(train_input[0])
print(train_output[0])
print('------------')
print(train.shape)
print(test.shape)
print('------------')
print(train.iloc[0])
print(test.iloc[0])

# print(train_input.shape[2])
# print(train_input.shape)

# print('__________________________________')
# print(test_input[1])
# print(test_output[1])

# In[1755]:

def trainLSTM(X, y, epochs=350, learning_rate=0.002):

    model = Sequential()
    model.add(InputLayer((WINDOW_SIZE, test_input.shape[2])))
    model.add(LSTM(20))
    model.add(Dense(4, 'linear'))
    model.add(Dense(1, 'linear'))

    check_point = ModelCheckpoint('model/best_model.keras', save_best_only=True, monitor='loss')
    model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=learning_rate), metrics=[RootMeanSquaredError()])

    model.fit(X, y, epochs=epochs, callbacks=[check_point])
    return model

# In[1756]:

model = trainLSTM(train_input, train_output)
print(model.history.history['loss'])
# loss vs. epochs graph
plt.figure(figsize=(10, 6))
plt.plot(model.history.history['loss'], label='Training Loss',linestyle='--')
# plt.plot(model.history.history['mse'], label='Training mse',linestyle='--')

mean_squared_error
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss vs. Epochs')
plt.legend()
plt.grid(True)
plt.show()

# In[1757]:

model = load_model('model/best_model.keras')


# In[1758]:

train_pred = model.predict(train_input)
test_pred = model.predict(test_input)

# In[1759]:

#/////////////////////////////////////////////////////////////////////////////////////////////
#/////////////////////////////////////////////////////////////////////////////////////////////
#/////////////////////////////////////////////////////////////////////////////////////////////
MAX=MAXs/1e4
MIN=MINs/1e4
#/////////////////////////////////////////////////////////////////////////////////////////////
#/////////////////////////////////////////////////////////////////////////////////////////////
#/////////////////////////////////////////////////////////////////////////////////////////////

train['CO2 eq'] = train['CO2 eq'] * (MAX - MIN) + MIN
test['CO2 eq'] = test['CO2 eq'] * (MAX - MIN) + MIN
test_forecast_df = test_pred * (MAX - MIN) + MIN
train_forecast_df = train_pred * (MAX - MIN) + MIN

print(train_forecast_df.shape)

# Plot the original train & test data along with the model's fitted values
plt.figure(figsize=(10, 5))


# Plot original training data
plt.plot(train['YEAR'], train['CO2 eq'], label='Training Data (Original Data)', marker='o', linestyle='solid')

# Plot original test data
plt.plot(test['YEAR'], test['CO2 eq'], label='Test Data (Original Data)', marker='o', linestyle='solid')





# print(fitted_series)

plt.plot(SPAIN['YEAR'].iloc[WINDOW_SIZE-1:WINDOW_SIZE-1+train_size],train_forecast_df, label='Training Data (FItted)', marker='o', linestyle='dashed')

# Plot model's predicted values for the test set
plt.plot(SPAIN['YEAR'].iloc[train_size+WINDOW_SIZE-1:], test_forecast_df, label='Test Data (Forecast)', marker='o', linestyle='dashed')




# Labels and formatting
plt.xlabel('Year')
plt.ylabel('kton CO2 eq 10e4')
plt.title('ARIMAX(p,d,q)')
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# In[1760]:

# Calculate and print the mean squared error for the test set only
train_forecast_df = train_forecast_df.flatten()
actual = test['CO2 eq'].iloc[WINDOW_SIZE-1:]
actual = np.array(actual)
test_forecast_df = np.array(test_forecast_df)
print(test_forecast_df)
print(actual)
mse = mean_squared_error(actual, test_forecast_df)
rmse = np.sqrt(mse)
msle = mean_squared_log_error(actual, test_forecast_df)
mae = mean_absolute_error(actual, test_forecast_df)
mape = np.mean(np.abs((actual - test_forecast_df) / actual)) * 100
med_ae = median_absolute_error(actual, test_forecast_df)
max_err = max_error(actual, test_forecast_df)
r2 = r2_score(actual, test_forecast_df)
evs = explained_variance_score(actual, test_forecast_df)

# Create a DataFrame for the errors
error_metrics = pd.DataFrame({
    'Metric': ['MSE', 'RMSE', 'MSLE', 'MAE', 'MAPE', 'MedianAE', 'Max error', 'R^2 score', 'EVS'],
    'Value': [mse, rmse, msle, mae, mape, med_ae, max_err, r2, evs]
})

# Define the styles for the table headers
styles = [
    {'selector': 'th', 'props': [('background-color', 'grey'), ('color', 'white'), ('font-size', '12pt'), ('text-align', 'center'), ('font-family', 'Arial')]},
    {'selector': 'td', 'props': [('background-color', 'white'), ('color', 'black'), ('font-size', '12pt'), ('text-align', 'center'), ('font-family', 'Arial')]},
    {'selector': 'caption', 'props': [('caption-side', 'top'), ('text-align', 'center'), ('font-size', '14pt'), ('font-weight', 'bold'), ('font-family', 'Arial')]}
]

# Display the table using pandas styling for better formatting in Jupyter Notebook
print("Statistics Before Preprocessing:")
display(error_metrics.style.set_table_styles(
    [{'selector': 'th', 'props': [('font-size', '12pt'), ('text-align', 'center')]},
     {'selector': 'td', 'props': [('font-size', '10pt'), ('text-align', 'center')]}])
    .set_caption("Statistics Before Preprocessing"))
